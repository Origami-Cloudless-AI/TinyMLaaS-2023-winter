{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class model_training():\n",
    "  if not os.path.exists('models'):\n",
    "        os.mkdir('models')\n",
    "  def __init__(self):\n",
    "    self.MODELS_DIR = 'models'\n",
    "    self.MODEL_TF = self.MODELS_DIR + 'model'\n",
    "    self.MODEL_NO_QUANT_TFLITE = self.MODELS_DIR + '/model_no_quant.tflite'\n",
    "    self.MODEL_TFLITE = self.MODELS_DIR + '/model.tflite'\n",
    "    self.MODEL_TFLITE_MICRO = self.MODELS_DIR + '/model.cc'\n",
    "    self.data_dir = 'data/'\n",
    "\n",
    "  def load_data(self, img_height, img_width, batch_size):\n",
    "    \"\"\"\n",
    "    Loads data from the directory provided in data_dir\n",
    "    \"\"\"\n",
    "\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "      self.data_dir,\n",
    "      validation_split=0.2,\n",
    "      subset=\"training\",\n",
    "      seed=123,\n",
    "      image_size=(img_height, img_width),\n",
    "      batch_size=batch_size)\n",
    "    \n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "      self.data_dir,\n",
    "      validation_split=0.2,\n",
    "      subset=\"validation\",\n",
    "      seed=123,\n",
    "      image_size=(img_height, img_width),\n",
    "      batch_size=batch_size)\n",
    "\n",
    "\n",
    "    return train_ds, val_ds\n",
    "\n",
    "\n",
    "  #Train the model 180x180 @ 32 batch size\n",
    "  def train_model(self, img_height, img_width, batch_size):\n",
    "    \"\"\"\n",
    "    Trains the model\n",
    "    \"\"\"\n",
    "    self.train_ds, self.val_ds = self.load_data(img_height, img_width, batch_size)\n",
    "\n",
    "    class_names = self.train_ds.class_names\n",
    "    \n",
    "    #Enable caching for training\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = self.train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = self.val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    model = Sequential([\n",
    "      layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "      layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Dropout(0.20),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(num_classes)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    epochs=5\n",
    "    history = model.fit(\n",
    "      train_ds,\n",
    "      validation_data=val_ds,\n",
    "      epochs=epochs\n",
    "    )\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    self.convert_model(model, train_ds)\n",
    "\n",
    "    return model, history, epochs_range\n",
    "\n",
    "  def convert_model(self, model, train_ds):\n",
    "    \"\"\"\n",
    "    Convert the model into TFLite format\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the model to the TensorFlow Lite format without quantization\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    model_no_quant_tflite = converter.convert()\n",
    "\n",
    "    # Save the model to disk\n",
    "    open(self.MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "    # Convert the model with quantization.\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    #uncomment to enable end-to-end int8-model, i.e. input and output is also int8/uint8.\n",
    "\n",
    "    #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    #converter.inference_input_type = tf.int8\n",
    "    #converter.inference_output_type = tf.int8\n",
    "\n",
    "    def representative_dataset():\n",
    "      for data in tf.data.Dataset.from_tensor_slices((train_ds)).batch(1).take(100):\n",
    "        yield [data[0]]\n",
    "\n",
    "    #converter.representative_dataset = representative_dataset\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # Save the model.\n",
    "    with open(self.MODEL_TFLITE, 'wb') as f:\n",
    "      f.write(tflite_model)\n",
    "\n",
    "  def prediction(self, model):\n",
    "    \"\"\"Predicts on the image provided in the path.\n",
    "\n",
    "    Args:\n",
    "        model (tflite model): tflite model to be used in the prediction\n",
    "\n",
    "    Returns:\n",
    "        img: image predicted, result: formatted string for the result\n",
    "    \"\"\"\n",
    "\n",
    "    path = '/data/1/1.png'\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (180,180))\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    result = (\"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(self.train_ds.class_names[np.argmax(score)], 100 * np.max(score)))\n",
    "    \n",
    "    return img, result\n",
    "\n",
    "  def plot_statistics(self, history, epochs_range):\n",
    "    \"\"\"\n",
    "    Plot the training statistics of the model to see over/underfitting etc.\n",
    "    \"\"\"\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    stats = plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    buff = BytesIO()\n",
    "    stats.savefig(buff, format=\"png\")\n",
    "    \n",
    "    return buff\n",
    "\n",
    "    # Compare size table\n",
    "  def plot_size(self,):\n",
    "\n",
    "      # Calculate size\n",
    "    size_no_quant_tflite = os.path.getsize(self.MODEL_NO_QUANT_TFLITE)\n",
    "    size_tflite = os.path.getsize(self.MODEL_TFLITE)\n",
    "\n",
    "    frame = pd.DataFrame.from_records(\n",
    "        [[\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \"],\n",
    "        [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
    "        columns = [\"Model\", \"Size\", \"\"], index=\"Model\")\n",
    "      \n",
    "    return frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
